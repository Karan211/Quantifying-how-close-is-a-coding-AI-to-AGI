
If two or more AI or/and people are capable to write in given* (quantum) programming language(s) a code for solving of test tasks created using the algorithm described in FIRST-NB.html from https://github.com/ogrnv/random-intelligence-tests, then their intelligence can be compared by comparing test results obtained using software applications based on the codes.

\* as an option - without language restrictions.

A few notes:

Due to the inevitable leakage of the best AI algorithms into other AI systems, there may be cases when an AI, which itself codes weak algorithms, adopts the best algorithm and demonstrates a high, but false, level of intelligence.

The question arises on the admissibility of informing AIs about systematic errors in their algorithms. Because this will add human intelligence to the AI ​​testing results.<p><br>
<b>The best known result of intelligence tests of AI-generated code for Prompt2 and example.c:</b><br><br>
8\*8 4 54 1 2 1000.00 Claude.ai Sonnet 4.5 us 2025-12-13 18:59:26 and infinite loops<p><br>
<b>Typical results of intelligence tests of AI-generated code for Prompt2 and example.c</b><br>
demonstrates that the more complex the tasks, the higher the probability of infinite loops:<br><br>
8\*8 <b>2</b> 54 1 2 <b>666.667</b> Deepseek-v3_1-terminus cn 2025-12-14<-- without infinite loops<br><br>
8\*8 <b>3</b> 54 1 2 <b>285.714</b> Deepseek-v3_1-terminus cn 2025-12-14<br>
8\*8 <b>3</b> 54 1 2 <b>000.000</b> Deepseek-v3_1-terminus cn 2025-12-14 <-- and infinite loops<br><br>
8\*8 <b>4</b> 54 1 2 <b>000.000</b> Deepseek-v3_1-terminus cn 2025-12-14 <-- infinite loops<br>

 * &nbsp;&nbsp;&nbsp;&nbsp;the number of:
 * &nbsp;&nbsp;&nbsp;&nbsp;cells of the board
 * &nbsp;&nbsp;&nbsp;&nbsp;chip types
 * &nbsp;&nbsp;&nbsp;&nbsp;chips on the board
 * &nbsp;&nbsp;&nbsp;&nbsp;rounds in a test
 * &nbsp;&nbsp;&nbsp;&nbsp;steps in a round
 * 1000 / average number of moves made per step
 * AI name
 * country
 * date and time of the code generation
